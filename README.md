# Data-Mining-in-Engineering

Focus area: Data analysis using Python.

ðŸ”‘ **key learnings:**
This course covers the theory and applications of data mining in
engineering.

It reviews fundamentals and key concepts of data
mining, discusses important data mining techniques, and presents
algorithms for implementing these techniques. 

In specific, this course covers data mining techniques for data preprocessing, association rule
extraction, classification, prediction, clustering, and complex data
exploration. 

Data mining applications in several areas including
manufacturing, healthcare, medicine, business, and other service
sectors are discussed.

# ðŸ“š Projects

## [#1 Explore Housing Price Trends](https://github.com/yvt-ee/Data-Mining-in-Engineering/blob/main/%231%20Explore%20Housing%20Market.ipynb)

Navigating and visualizing the housing data using Python, leveraging libraries like Pandas, Matplotlib, and Seaborn. Explore, clean, visualize, and analysis data effectively.


## [#2 Principal Component Analysis (PCA) for Wine dataset](https://github.com/yvt-ee/Data-Mining-in-Engineering/blob/main/%232%20PCA%20for%20Wine%20dataset.ipynb)
Principal Component Analysis (PCA) is a powerful dimensionality reduction technique that transforms a large set of variables into a smaller set, retaining most of the essential information from the original dataset. In the context of the Wine dataset, which contains various chemical properties of different wine varieties, PCA can be applied to reduce the dataset's complexity while preserving its core characteristics. This process can be efficiently implemented using libraries like sklearn.

## [#3 K-Nearest_Neighbors_for_random_dataset](https://github.com/yvt-ee/Data-Mining-in-Engineering/blob/main/%233%20K-Nearest_Neighbors_for_random_dataset.ipynb)
The K-Neighbors Classifier, also known as K-Nearest Neighbors (KNN), is a supervised machine learning algorithm commonly used for classification tasks. It classifies new data points based on their similarity to the closest 'neighbors' in the feature space, measured by distance metrics such as Euclidean distance. This simple yet effective algorithm can be easily implemented using libraries like scikit-learn sklearn.
